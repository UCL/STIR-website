<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
  <head>
    <style>
table, th, td {
    vertical-align: top;
}
</style>
    <title>STIR User's and Developer's Meeting 2023</title>
  </head>
<meta http-equiv="cache-control" content="no-cache"/>
<meta http-equiv="pragma" content="no-cache"/>

<BODY bgcolor="fdffe6" text="000000" link="0000ff" vlink="800080">

    <h1>STIR User's and Developer's Meeting 2023</h1>
<!--<img src="STIR2023-presenters-organisers.jpg" alt="Presenters and organisers" style="float:right;width:500px;height:450px;">
-->

<h2>Organisers</h2>
<ul>
<li> Daniel Deidda, National Physical Laboratory, UK</li>
<li> Nikos Efthimiou, MGH, USA</li>
<li> Charalampos Tsoumpas, University of Groningen, Nederland</li>
</ul>

<h2>Where and when</h2>
<ul>
  <li>Thursday, 10 November, 18:30-20:30 in Vancouver, Canada timezone (PST, UTC-8).<br />
      Friday, 11 November 2:30-4:30 in London, UK timezone (UTC)</li>
  <li>During the <a href=https://nssmic.ieee.org/2023/>IEEE NSS-MIC</a>, but also accessible online</li>
  <!--
   <li>This year the event took place in Milan, Italy during the IEEE NSS-MIC and you can find more information at the
    <a href="https://www.eventclass.org/contxt_ieee2023/scientific/online-program/session?s=STIR" target="_blank">conference main website</a>.
  </li>
-->
  
  <li>Join online via Teams using one of the following:
    <ul>
      <li> <a href="https://teams.microsoft.com/l/meetup-join/19%3ameeting_YzFkZDg4MjgtMmNiMS00OWNiLWJmMTEtOWYzM2Q1ODk5ZGY5%40thread.v2/0?context=%7b%22Tid%22%3a%221faf88fe-a998-4c5b-93c9-210a11d9a5c2%22%2c%22Oid%22%3a%229b8c9b0f-6d53-4329-82f9-dfb3c3276b4f%22%7d" target="_blank">Teams Meeting via this link</a>.</li>
      <li><a href="https://www.microsoft.com/microsoft-teams/join-a-meeting" target="_blank">Join on the Web</a> with Meeting ID: 358 216 710 88, Passcode: hukpKv</li>
      <li>Call in (audio only): <a href="https://dialin.teams.microsoft.com/e0ab7027-6c86-452b-9160-049529c91a7a?id=642370726" target="_blank">Find a local number</a>, and use
        Phone Conference ID: 642 370 726#
      </li>
    </ul>
  </li>

</ul>

<!-- <p>Please test your connection prior to the meeting here:<a href=https://ukri.zoom.us/test target="_blank">https://ukri.zoom.us/test</a>.</p>
-->

<h2>Summary</h2>
  <p>During this annual meeting users and developers presented their recent work with STIR with the emphasis on
  software and algorithmic development.
  In this meeting, we encourage participation and sharing. Early and preliminary works are welcomed.</p>
<!--
  This year, the meeting was online only, and attended by about 40 people.
Some speakers have kindly provided PDFs of their talks, see the table below. In addition, all speakers have agreed to making the 
<a href=http://www.ccpsynerbi.ac.uk/sites/www.ccppetmr.ac.uk/files/CCPSyneRBI/STIRMeeting20231203.mp4>recording of the meeting</a> available.</p>
<p> Please note that this material 
is provided under the Creative Commons 
<a href="http://creativecommons.org/licenses/by-nd/4.0/" target=_blank>"Attribution-NoDerivs" license</a>,
      allowing redistribution without modification with credit to the author(s).</p>
-->
<p>For up-to-date information on this meeting please always check the STIR website.</p>


<!--
<h2>Registration and abstract submission</h2>
<p>
  <strong>Deadline for abstract submission: 20th of October</strong>
</p>
    <p>
  Registration is required for in-person attendance.
    Attendance is free of charge without dinner, but if you wish to reserve space and a dinner box you will need to register your attendance via the official IEEE NSS/MIC registration to the event with a very small charge.
    </p>

<p>
    If you are interested in presenting your recent work using and/or extending the STIR library,
    submit an abstract via the <a href="https://eventclass.org/contxt_ieee2023/" target="_blank">official conference website (Submit a new contribution)</a>.
    Although the abstract submission is closed for the main conference, it is still open for the workshops including our meeting.
    If your abstract is accepted, it will feature as part of the IEEE conference in the official program of the meeting.
    (Note that as the conference allows virtual attendance, you can also present remotely in this workshop).
    </p>
-->
<!--
<h2>Recording</h2>
<p><a href=http://www.ccpsynerbi.ac.uk/sites/www.ccppetmr.ac.uk/files/CCPSyneRBI/STIRMeeting20231203.mp4>Recording of the meeting.</a></p>
-->

<h2>Schedule</h2>
<p>See the <a href="https://eventclass.org/contxt_ieee2023/scientific/online-program/session?s=STIR">IEEE MIC session information</a> for timing etc.</p>
<!--
    <p>Click on the title to get a PDF of the presentation.<br />
      Please note that PDFs and recordings are provided under the Creative Commons 
      <a href="http://creativecommons.org/licenses/by-nd/4.0/" target=_blank>"Attribution-NoDerivs" license</a>,
      allowing redistribution without modification with credit to the author(s).</p> -->
<table class="table table-striped" style="padding: 2em auto 1em;">
  <tbody>
    <tr id="e1720">
      <td>
        <details>
          <summary>
            <strong>Integrating SIMIND Monte Carlo Simulator with SIRF for Improved SPECT Reconstructions</strong><br>
            <u><strong>S. D. Porter</strong></u><sup>1, 2</sup>, R. Gillen<sup>1, 3</sup>, D. Deidda<sup>2, 1</sup>, K. Thielemans<sup>1</sup>
          </summary>
          <p><sup>1</sup> University College London, Institute of Nuclear Medicine, London, United Kingdom<br /><sup>2</sup> National Physical Laboratory, London, United Kingdom<br /><sup>3</sup> NHS Greater Glasgow and Clyde, Glasgow, United Kingdom</p>                                                
          <p><strong>Abstract</strong></p><p>Accurate scatter correction is essential for high-quality SPECT images. Traditional methods, such as the Triple Energy Window (TEW) correction, which inevitably results in a loss of Poisson statistics, are unsuitable for imaging scenarios with a continuous energy spectrum. An example of such a scenario is Bremsstrahlung SPECT imaging. In these cases, estimating scatter using a Monte Carlo (MC) simulator during the reconstruction process has proven advantageous. This presentation describes&nbsp;the integration of the SIMIND MC simulator with the Synergistic Image Reconstruction Framework (SIRF) and presents some preliminary results.</p>
          
          <p>The talk will begin by highlighting the potential applications of MC-simulated projection and scatter data in image reconstruction and then will introduce the SIRF-integrated SIMINDSimulator class, elaborating on its role as both a scatter estimator and forward projector. We will compare its performance with SIRF&#39;s STIR forward projector and benchmark it against real-world data.</p>
          
          <p>Subsequently, the talk will showcase the application of the SIRF-integrated SIMINDSimulator within an OSEM reconstruction framework. Here, scatter is dynamically estimated at each epoch, using&nbsp;the current image as a source map. The reconstructed images will be compared against both uncorrected and TEW-corrected images, using Lu177 and Tc99m NEMA phantom data as examples.</p>
          
          <p>Finally, potential&nbsp;future areas for development will be discussed. This includes the integration of SIMIND into STIR Python and the potential for SIMIND to be used as both a ScatterEstimator and Projector within an acquisition model.</p>
          <p><em>Acknowledgments:</em>This work was supported in part by the National Physics Laboratory through the National Measurement System of the UK Department of Business, Energy, and Industrial Strategy.
            The software used in this project is maintained by CCP SyneRBI (EPSRC grant EP/T026693/1) and CCPi (EPSRC grant (EP/T026677/1).
          <p><em>Keywords</em>: SPECT, Monte Carlo, SIMIND, Scatter
        </details>
      </td>
    </tr>
    
    <tr id="e1695">
      <td>
        <details>
          <summary>
            <strong>A Reconstruction Algorithm for Dynamic PET</strong><br>
            <strong><u>Y. Qranfal</u></strong><sup>1</sup>
          </summary>
          <p><sup>1</sup> Wentworth Institute of Technology, School of Computing and Data Science, Boston, Massachusetts, United States of America</p>                                                
          <p><strong>Abstract</strong></p><p>In this talk, we see how we model and solve the inverse problem of reconstructing a dynamic medical image where the signal strength changes substantially over the time required for data acquisition. We use a stochastic approach based on a Markov process to model the problem. We introduce a novel proximal approach and apply it during the Kalman filter algorithm to ensure positivity. We test our method for the case of image reconstruction in time-dependent photon emission tomography (PET). Numerical results corroborate the effectiveness of our approach.</p>
          <p><em>Keywords</em>: PET, Reconstruction, Dynamic, Image
        </details>
      </td>
    </tr>
    <tr id="e1696">
      <td>
        <details>
          <summary>
            <strong>Investigating the impact of Multi-TOF Kernel Reconstruction in PET Imaging with heterostructured Scintillators</strong><br>
            <u><strong>C. Lowis</strong></u><sup>1, 2</sup>, N. Efthimiou<sup>3</sup>, P. Mohr<sup>4</sup>, F. Pagano<sup>1, 5</sup>, M. Pizzichemi<sup>5</sup>, C. Tsoumpas<sup>4</sup>, K.-J. Langen<sup>2</sup>, K. Ziemons<sup>6</sup>, E. Auffray<sup>1</sup>
          </summary>
          <p><sup>1</sup> CERN, Geneva, Gen√®ve, Switzerland<br /><sup>2</sup> RWTH Aachen University, Aachen, North Rhine-Westphalia, Germany<br /><sup>3</sup> Athinoula A. Martinos Center for Biomedical Imaging: Boston, Boston, Massachusetts, United States of America<br /><sup>4</sup> University Medical Center Groningen, Groningen, Netherlands<br /><sup>5</sup> University of Milano-Bicocca, Milan, Italy<br /><sup>6</sup> FH Aachen - University of applied sciences, Aachen, North Rhine-Westphalia, Germany</p>                        <p class="contributionCollaboration">This work was carried out in the frame of the Crystal Clear Collaboration</p>                        
          <p><strong>Abstract</strong></p><p>Positron Emission Tomography (PET) is a potent imaging tool in medical diagnostics and molecular imaging. It detects coincident gamma rays from a tracer that emits positrons. In Time of Flight (TOF) PET, the time arrival difference between these coincident gamma rays is also used to optimize image quality by improving spatial resolution and signal-to-noise ratio. In TOF-PET image reconstruction, a single timing kernel is traditionally used to model the distribution of Coincidence Time Resolution (CTR). Nevertheless, the latest advancements in TOF-PET module concept, particularly in heterostructured scintillators, call for a more complex approach to CTR distribution modeling.<br />
            This research aims to explore the benefits of using a multi-TOF kernel Maximum Likelihood Expectation Maximization (MLEM) algorithm to model the CTR distribution of heterostructured scintillators instead of the conventional single-kernel method.<br />
            We conducted simulations of a PET scanner fitted with heterostructured scintillators and a NEMA (IQ) phantom using the GATE toolkit (v8.2). We utilized the open-source toolkit Software for Tomographic Image Reconstruction (STIR) for the image reconstruction. We tested multi-kernel approaches for heterostructured scintillators and a single kernel for the conventional approach.<br />
            Our goal is to explore and better understand the impact of multiple TOF kernels and intricate CTR distributions on image quality, which may yield promising results.</p>
          <p><em>Acknowledgments:</em>This work was carried out in the frame of the Crystal Clear Collaboration. It is sponsored by the Wolfgang Gentner Programme of the German Federal Ministry of Education and Research (grant no. 13E18CHA) and it received support from the CERN Budget for Knowledge Transfer to Medical Applications.
          <p><em>Keywords</em>: TOF-PET, Heterostructure, Multiple TOF kernels, Image Reconstruction
        </details>
      </td>
    </tr>
    <tr id="e1725">
      <td>
        <details>
          <summary>
            <strong>Integration of STIR With Deep Learning Libraries</strong><br>
            <u><strong>I. R.D. Singh</strong></u><sup>1</sup>, S. Porter<sup>1</sup>, R. Barbano<sup>2</sup>, Z. Kereta<sup>1</sup>, K. Thielemans<sup>1</sup>
          </summary>
          <p><sup>1</sup> University College London, London, United Kingdom<br /><sup>2</sup> Technical University of Munich, Munich, Germany</p>                                                
          <p><strong>Abstract</strong></p><p>STIR&nbsp;gives access to a range of tools that allow researchers to implement reconstruction algorithms on raw clinical SPECT&nbsp;and PET&nbsp;data. Over the last few years, Deep Learning (DL) has become ubiquitous for its use in reconstruction. The DL&nbsp;methods require, to varying degrees, that the reconstructions are consistent with the measurements from scanners. To this end, one must integrate the measurement-consistency within a DL framework. In this work we show how simply STIR can be integrated into established DL libraries.</p>
          
          <p>DL requires the &ldquo;training&rdquo; of sophisticated neural network architectures that is done by leveraging (reverse-mode) Automatic Differentiation (AD) and (stochastic) first-order optimisation algorithms. Briefly, AD allows the computation of gradients from an objective function to the network parameters that allow first-order optimisation algorithms to update the parameters. To integrate STIR with a DL library&rsquo;s AD one must enable access to the value and gradient of the computation.</p>
          
          <p>In the case of PyTorch (a popular DL framework), the STIR objective function is wrapped by subclassing torch.autograd.Function. In the forward method the value of the objective for an input image is computed, in the backward method the gradient of the objective for the same input image. By integrating this function one can utilise the PyTorch&rsquo;s optimisers to&nbsp;optimise the STIR Poisson objective function and update the image. Results of PyTorch-optimised reconstruction and implementation will be shown.</p>
          
          <p>Further, an attempt will be made to integrate Google&rsquo;s JAX with STIR.</p>
          <p><em>Acknowledgments:</em>This work is supported by&nbsp;the EPSRC-funded UCL Centre for Doctoral Training in Intelligent, Integrated Imaging in Healthcare (i4Health) (EP/S021930/1), Department of Health&rsquo;s NIHR-funded Biomedical Research Centre at University College London Hospitals,&nbsp;UK EPSRC grant EP/X010740/1,&nbsp;UK EPSRC EP/V026259/1. Software used in this project is partially maintained by CCP SyneRBI (EPSRC EP/T026693/1).
          <p><em>Keywords</em>: Deep Learning, PyTorch, JAX, STIR
            
        </details>
      </td>
    </tr>
    
    <tr id="e1697">
      <td>
        <details>
          <summary>
            <strong>Reconstruction from Siemens Biograph Vision 600 TOF data with STIR</strong><br>
            <u><strong>N. Jurjew</strong></u><sup>1</sup>, D. Atkinson<sup>2</sup>, K. Thielemans<sup>1, 3</sup>
          </summary>
          <p><sup>1</sup> University College London, Institute of Nuclear Medicine, London, United Kingdom<br /><sup>2</sup> University College London, Centre for Medical Imaging, London, United Kingdom<br /><sup>3</sup> University College London, Centre for Medical Image Computing, London, United Kingdom</p>                                                
          <p><strong>Abstract</strong></p><p>STIR is designed to be able to deal with many clinical scanners that are currently used, including the Siemens Biograph mMR, GE Signa PET/MR, GE Discovery MI etc. So far, however, STIR has not been used to reconstruct time of flight (TOF) data acquired on the Siemens Biograph Vision 600. This is particularly challenging as sinogram data have been &ldquo;mashed&rdquo; by combining views and TOF bins with a proprietary method to reduce data-size and computation. In this work, we adapted some STIR functionalities such that reconstructions from Vision TOF data were made feasible with STIR.</p>
          
          <p>Phantom measurements were performed on the Siemens Biograph Vision 600 PET/CT. Time of flight PET raw data were acquired and a CT was performed to use for attenuation and scatter correction. Subsequently, the Siemens research software &ldquo;e7tools&rdquo; was used for binning of prompts into sinograms, scatter and random estimation as well as mu-map generation from CT data and normalization generation. The output was generated in Siemens-interfile format.</p>
          
          <p>With the information in the interfile headers, this data was visualized in a common medical image viewer (AMIDE). In order to read the data with SIRF &amp; STIR, compatible headers for all files had to be created. In addition, STIR functions had to be adapted to deal with scanner-specific keywords and bin-orders.</p>
          Results will be shown for OSEM reconstructions of the phantom measurements using SIRF, relying on STIR for PET modelling.
          <p><em>Acknowledgments:</em>The authors would like to thank the team members&nbsp;of Siemens Medical Solutions USA, Inc., Knoxville, TN, namely Paul Schleyer, Inki Hong and Mohammadreza Teimoorisichani, for their support in handling the Siemens Research Software &quot;e7tools&quot; and their support regarding data format. NJ is completing a PhD with funding from EP-SRC CDT i4Health (EP/S021930/1) and Siemens Healthineers - Magnetic Resonance. Software used for this work is maintained with funding by CCP SyneRBI (EPSRC grant EP/T026693/1).
          <p><em>Keywords</em>: PET image reconstruction, PET raw data
            
        </details>
      </td>
    </tr>
    <tr id="e1698">
      <td>
        <details>
          <summary>
            <strong>Integration and benchmarking of the parallelproj GPU projectors into STIR</strong><br>
            <u><strong>G. Schramm</strong></u><sup>1</sup>, K. Thielemans<sup>2, 3</sup>
          </summary>
          <p><sup>1</sup> KU Leuven, Department of Imaging and Pathology, Leuven, Belgium<br /><sup>2</sup> University College London, Institute of Nuclear Medicine,, London, United Kingdom<br /><sup>3</sup> University College London, Centre for Medical Image Computing,, London, United Kingdom</p>                                                
          <p><strong>Abstract</strong></p><p>In this work, we discuss the integration of the Parallelproj Joseph Non-TOF CUDA GPU projectors into STIR v5.0/5.1. The performance of the new projectors is benchmarked against existing non-GPU projectors using the new STIR projection timing tool. We find that, when compared to the existing PRMT CPU projector, for a non-TOF span-1 sinogram of a GE DMI 4 geometry, including 8 views, Parallelproj CUDA GPU forward and back projections are faster by a factor of 7.8 (68 ms vs. 535 ms) and 3 (256 ms vs. 771 ms), respectively using an AMD Ryzen 9 5900 12-Core Processor and a GEForce RTX 3070 GPU. As an outlook, we also present and discuss benchmark results of parallelproj for TOF projections and different computing modes (e.g. direct GPU mode) not yet available in STIR.</p>
          <p><em>Keywords</em>: PET reconstruction, projections, GPU, CUDA
            
        </details>
      </td>
    </tr>
    <tr id="e1726">
      <td>
        <details>
          <summary>
            <strong>STIR status and future functionality</strong><br>
            <u><strong>K. Thielemans</strong></u><sup>1, 2</sup>, D. Deidda<sup>3</sup>, N. Efthimiou<sup>4</sup>, C. Tsoumpas<sup>5</sup>
          </summary>
          <p><sup>1</sup> University College London, Institute for Nuclear Medicine, London, United Kingdom<br /><sup>2</sup> University College London, Centre for Medical Image Computing, London, United Kingdom<br /><sup>3</sup> National Physical Laboratory, Nuclear Medicine, London, United Kingdom<br /><sup>4</sup> Massachusetts General Hospital and Harvard Medical School, Athinoula A. Martinos Center for Biomedical Imaging, Charlestown, Massachusetts, United States of America<br /><sup>5</sup> Rijksuniversiteit Groningen, University Medical Center Groningen, Groningen, Netherlands</p>                                                
          <p><strong>Abstract</strong></p><p>In this talk we will give an overview of recent and upcoming features in STIR and plans for future releases. In addition, we will discuss the relation of STIR with the open source Synergistic Image Reconstruction Framework from the UK Collaborative Computational Project (CCP) in Synergistic Image Reconstruction for Biomedical Imaging (SyneRBI). We will also discuss a potential role of STIR in the new standard for PET raw data under development by the Emission Tomography Standardization Initiative (ETSI). We will end with an open discussion on the future of STIR with an opportunity to discuss desired features and how these could be implemented.</p>
          <p><em>Acknowledgments:</em>STIR is part-maintained by the UKRI EPSRC grant to&nbsp;Collaborative Computational Project (CCP) in Synergistic Image Reconstruction for Biomedical Imaging (SyneRBI) (EP/T026693/1)
          <p><em>Keywords</em>: open-source software, image reconstruction, PET, SPECT
            
        </details>
      </td>
    </tr>
    <tr id="e1732">
      <td>
        <details>
          <summary>
            <strong>Discussion</strong><br>
          </summary>                      
          <p>This is a time for users and developers  to discuss about functionality that they would like to have and/or develop.</p>
        </details>
      </td>
    </tr>
  </tbody>
</table>



<h2>Acknowledgements</h2>
<p>Many thanks to <a href="http://www.ccpsynerbi.ac.uk" target=_blank>CCP SyneRBI</a> for
  sponsoring this event, and to the MIC organisers and in particular Ralf Engels for assistance.</p>

<!--
    <h2>Photo</h2>
<p>We took a picture at the end of the meeting, with many people already signed out unfortunately.</p>
<center>
  <img SRC=AttendeePhoto.png WIDTH="800" BORDER=0 ALT="attendees">
</center>
-->

<h2>Previous meetings</h2>
<ul>
  <li><a href="../MIC2004workshop/homepage.html">2004</a></li>
  <li><a href="../MIC2009UsersMeeting/homepage.html">2009</a></li>
  <li><a href="../MIC2011UsersMeeting/homepage.shtml">2011</a></li>
  <li><a href="../MIC2012UsersMeeting/homepage.shtml">2012</a></li>
  <li><a href="../MIC2013UsersMeeting/homepage.shtml">2013</a></li>
  <li><a href="../MIC2014UsersMeeting/homepage.shtml">2014</a></li>
  <li><a href="../MIC2015UsersMeeting/homepage.shtml" target="_parent">2015</a></li>
  <li><a href="../MIC2016UsersMeeting/homepage.shtml" target="_parent">2016</a></li>
  <li><a href="../MIC2017UsersMeeting/homepage.shtml" target="_parent">2017</a></li>
  <li><a href="../MIC2018UsersMeeting/homepage.shtml" target="_parent">2018</a></li>
  <li><a href="../MIC2019UsersMeeting/homepage.shtml" target="_parent">2019</a></li>
  <li><a href="../2020UsersMeeting/homepage.shtml" target="_parent">2020</a></li>
  <li><a href="../2022UsersMeeting/homepage.shtml" target="_parent">2022</a></li>
</ul>

<hr>
<p>
  <!-- hhmts start -->
  Last modified: 29 October 2024
  <!-- hhmts end -->
</p>
</body>
</html>
